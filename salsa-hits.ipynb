{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Netowrk Analysis Of Births In The United States\n",
    "\n",
    "This Notebook Processes Data Of Births In The US With The Goal To Locate The Importers And Exporters Of Childbirth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This Cell Contains All Needed Imports To Run This Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Mock File\n",
    "\n",
    "This Cell Can Create A Mock File. Due To Confidentiality Reasons, The Raw Data Cannot Be Uploaded. However, The Data Can Be Obtained From Making A Request For It Here: https://www.cdc.gov/nchs/nvss/index.htm\n",
    "\n",
    "*Note: A Mock File Has Already Been Created And Uploaded For Use*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMockData():\n",
    "    \"\"\"\n",
    "    Creates Mock File For Analysis\n",
    "\n",
    "    Returns:\n",
    "    None: Saves The Result To A CSV File.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load The FIPS codes\n",
    "    dfDummy = pd.read_csv('./county_codes.csv')\n",
    "\n",
    "    fips_codes = dfDummy['FIPS'].values\n",
    "\n",
    "    # Generate Random FIPS Codes For 'OC_County_FIPS' And 'MR_County_FIPS'\n",
    "    mock_data = pd.DataFrame({\n",
    "        'OC_County_FIPS': np.random.choice(fips_codes, size=100),\n",
    "        'MR_County_FIPS': np.random.choice(fips_codes, size=100),\n",
    "    })\n",
    "\n",
    "    # Save The Mock Data To A CSV File\n",
    "    mock_data.to_csv('mock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Graph From Input Data\n",
    "\n",
    "This Cell Creates A Graph To Use For The Analysis.\n",
    "- `buildGraph` Function To Build A Graph Using Distinct Pairs As Nodes, And All Pairs As Edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(dataframe):\n",
    "    \"\"\"\n",
    "    Creates Graph From File Source - Destination Pairs\n",
    "\n",
    "    Args:\n",
    "    dataframe (pd.DataFrame): Table Of Source - Destination Pairs \n",
    "    \n",
    "    Returns:\n",
    "    nx.DiGraph: A Graph Object Created From Pairs And Numbers Of Pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    nodes = dataframe[[\"OC_County_FIPS\", \"MR_County_FIPS\"]].drop_duplicates().values.flatten()\n",
    "    edges = list(zip(dataframe[\"OC_County_FIPS\"], dataframe[\"MR_County_FIPS\"]))\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing The Social Network Analysis\n",
    "\n",
    "This Cell Will Run The Analysis With The Created Graph.\n",
    "\n",
    "- `salsa_algorithm` Runs SALSA With Convergence Criteria\n",
    "\n",
    "- `process_data_and_run_algorithms` Runs HITS And Calls The SALSA Function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SALSA: 100%|██████████| 100/100 [00:00<00:00, 5384.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# SALSA Algorithm (Convergence Criteria Can Be Changed)\n",
    "def salsa_algorithm(G, max_iter=100, tol=1.0e-6):\n",
    "    \"\"\"\n",
    "    Runs SALSA Social Network Analysis\n",
    "\n",
    "    Args:\n",
    "    G (nx.DiGraph): Directed Graph Of Pairs\n",
    "    max_iter (int): Number Of Iterations\n",
    "    tol (float): Tolerence Level\n",
    "    \n",
    "    Returns:\n",
    "    : A Graph Object Created From Pairs And Numbers Of Pairs.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    nodes = G.nodes()\n",
    "\n",
    "    hubs = {node: 1 for node in nodes}\n",
    "    authorities = {node: 1 for node in nodes}\n",
    "\n",
    "    for _ in tqdm(range(max_iter), desc=\"Running SALSA\"):  \n",
    "        # Authority Update Step\n",
    "        new_authorities = {}\n",
    "        for node in nodes:\n",
    "            new_authorities[node] = sum(\n",
    "                hubs[neighbor] for neighbor in G.predecessors(node)\n",
    "            )\n",
    "\n",
    "        # Hub Update Step\n",
    "        new_hubs = {}\n",
    "        for node in nodes:\n",
    "            new_hubs[node] = sum(\n",
    "                authorities[neighbor] for neighbor in G.successors(node)\n",
    "            )\n",
    "\n",
    "        # Normalize\n",
    "        auth_sum = sum(new_authorities.values())\n",
    "        hub_sum = sum(new_hubs.values())\n",
    "\n",
    "        for node in nodes:\n",
    "            new_authorities[node] = new_authorities[node] / auth_sum\n",
    "            new_hubs[node] = new_hubs[node] / hub_sum\n",
    "\n",
    "        # Check For Convergence\n",
    "        err = sum(\n",
    "            abs(new_authorities[node] - authorities[node]) for node in nodes\n",
    "        ) + sum(abs(new_hubs[node] - hubs[node]) for node in nodes)\n",
    "        if err < tol:\n",
    "            break\n",
    "\n",
    "        hubs, authorities = new_hubs, new_authorities\n",
    "\n",
    "    return hubs, authorities\n",
    "\n",
    "def process_data_and_run_algorithms(dataframe):\n",
    "    G = buildGraph(dataframe)\n",
    "    salsa_hubs, salsa_authorities = salsa_algorithm(G)\n",
    "    hits_hubs, hits_authorities = nx.hits(G, max_iter=100, tol=1.0e-6)\n",
    "    nodes = list(G.nodes())\n",
    "    salsa_hub_scores = [salsa_hubs[node] for node in nodes]\n",
    "    salsa_authority_scores = [salsa_authorities[node] for node in nodes]\n",
    "    hits_hub_scores = [hits_hubs[node] for node in nodes]\n",
    "    hits_authority_scores = [hits_authorities[node] for node in nodes]\n",
    "\n",
    "    dfScores = pd.DataFrame({\n",
    "        \"County\": nodes,\n",
    "        \"SALSA_Hub_Score\": salsa_hub_scores,\n",
    "        \"SALSA_Authority_Score\": salsa_authority_scores,\n",
    "        \"HITS_Hub_Score\": hits_hub_scores,\n",
    "        \"HITS_Authority_Score\": hits_authority_scores,\n",
    "    })\n",
    "    return dfScores\n",
    "\n",
    "# Example Usage With A Mock Dataframe:\n",
    "df = pd.read_csv(\"mock_data.csv\")\n",
    "scores = process_data_and_run_algorithms(df)\n",
    "scores.to_csv(\"scores.csv\", index=False)\n"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
